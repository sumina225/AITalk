import cv2
import numpy as np
import pandas as pd
import os
from deepface import DeepFace
from mtcnn import MTCNN

DB_PATH = "child_face_db.csv"
detector = MTCNN()  # MTCNN ì‚¬ìš© (í‚¤í¬ì¸íŠ¸ í¬í•¨)
THRESHOLD = 0.7  # ì„ê³„ê°’ (í…ŒìŠ¤íŠ¸ì— ë”°ë¼ ì¡°ì •)


def get_available_camera():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ ì¸ë±ìŠ¤ë¥¼ ìë™ìœ¼ë¡œ ì°¾ëŠ” í•¨ìˆ˜"""
    for i in range(5):
        cap = cv2.VideoCapture(i, cv2.CAP_DSHOW)
        if cap.isOpened():
            print(f"âœ… ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼: {i}ë²ˆ")
            cap.release()
            return i
    print("ğŸš¨ ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ê°€ ì—†ìŠµë‹ˆë‹¤!")
    return None


def warmup_camera(cap):
    """ì¹´ë©”ë¼ ì›Œë°ì—… (3í”„ë ˆì„ ìŠ¤í‚µ)"""
    for _ in range(3):
        ret, _ = cap.read()
        if ret:
            print("[INFO] ì¹´ë©”ë¼ ì›Œë°ì—… ì™„ë£Œ")
            break


def align_face(frame, face):
    """
    ì–¼êµ´ ì •ë ¬ í•¨ìˆ˜.
    MTCNNì˜ ê²€ì¶œ ê²°ê³¼(face dict)ì—ì„œ 'box'ì™€ 'keypoints'ë¥¼ ì‚¬ìš©í•˜ì—¬,
    ì¢Œìš° ëˆˆì˜ ê°ë„ë¥¼ ê³„ì‚°í•˜ê³ , í•´ë‹¹ ê°ë„ë¡œ ì–¼êµ´ ì˜ì—­ì„ íšŒì „ì‹œí‚µë‹ˆë‹¤.
    """
    box = face['box']  # [x, y, w, h]
    keypoints = face['keypoints']
    x, y, w, h = box
    # ì›ë³¸ frameì—ì„œ ì–¼êµ´ ì˜ì—­ì„ crop
    face_img = frame[y:y + h, x:x + w]
    # keypointsë¥¼ ì–¼êµ´ ì˜ì—­ì— ë§ê²Œ ì¡°ì •
    left_eye = (keypoints['left_eye'][0] - x, keypoints['left_eye'][1] - y)
    right_eye = (keypoints['right_eye'][0] - x, keypoints['right_eye'][1] - y)
    # ë‘ ëˆˆ ì‚¬ì´ì˜ ê°ë„ ê³„ì‚°
    dx = right_eye[0] - left_eye[0]
    dy = right_eye[1] - left_eye[1]
    angle = np.degrees(np.arctan2(dy, dx))
    # ì–¼êµ´ ì¤‘ì‹¬ ê³„ì‚°
    center = (w // 2, h // 2)
    M = cv2.getRotationMatrix2D(center, angle, 1)
    aligned_face = cv2.warpAffine(face_img, M, (w, h))
    return aligned_face


def preprocess_face(face_img):
    """ì–¼êµ´ ì „ì²˜ë¦¬: BGRâ†’RGB ë³€í™˜ ë° 160x160 ë¦¬ì‚¬ì´ì¦ˆ"""
    face_img = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)
    face_img = cv2.resize(face_img, (160, 160))
    return face_img


def extract_embedding(processed_face, model="ArcFace"):
    """DeepFaceë¥¼ ì´ìš©í•´ ì–¼êµ´ ì„ë² ë”© ì¶”ì¶œ (512ì°¨ì›)"""
    try:
        analysis = DeepFace.represent(
            processed_face,
            model_name=model,
            detector_backend="mtcnn",
            enforce_detection=False
        )
        if not analysis or "embedding" not in analysis[0]:
            return None
        embedding = np.array(analysis[0]['embedding'], dtype=float)
        # ë§Œì•½ 128ì°¨ì› ë²¡í„°ê°€ ë‚˜ì˜¤ë©´ 512ì°¨ì›ìœ¼ë¡œ íŒ¨ë”©
        if embedding.shape[0] == 128:
            embedding = np.pad(embedding, (0, 384), mode="constant")
        return embedding
    except Exception as e:
        print(f"[ERROR] ì–¼êµ´ ë²¡í„° ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return None


def register_child_face(child_id: int, child_name: str):
    """
    ì•„ë™ ì–¼êµ´ ë“±ë¡: ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ì—ì„œ ìµœëŒ€ 15íšŒ ì‹œë„ ì¤‘ 5ê°œ í’ˆì§ˆ ì¢‹ì€ ìƒ˜í”Œì„ ìˆ˜ì§‘.
    ì–¼êµ´ ì •ë ¬ í›„ ì „ì²˜ë¦¬í•˜ì—¬ ì„ë² ë”©ì„ ì¶”ì¶œí•˜ê³  CSVì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    camera_index = get_available_camera()
    if camera_index is None:
        return {"status": 503, "message": "ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ê°€ ì—†ìŠµë‹ˆë‹¤."}

    cap = cv2.VideoCapture(camera_index, cv2.CAP_DSHOW)
    if not cap.isOpened():
        return {"status": 503, "message": "ì¹´ë©”ë¼ ì—°ê²° ì˜¤ë¥˜."}

    warmup_camera(cap)

    # DB íŒŒì¼ ë¡œë“œ (ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±)
    if not os.path.exists(DB_PATH):
        df = pd.DataFrame(columns=["child_id", "child_name"] + [f"v{i}" for i in range(512)])
    else:
        df = pd.read_csv(DB_PATH, dtype={'child_id': int, 'child_name': str})
    df = df[df["child_id"] != child_id]

    samples = []
    attempts = 0
    while len(samples) < 5 and attempts < 15:
        ret, frame = cap.read()
        attempts += 1
        if not ret:
            print("[ERROR] ì´ë¯¸ì§€ ìº¡ì²˜ ì‹¤íŒ¨. ë‹¤ì‹œ ì‹œë„ ì¤‘...")
            continue
        frame = cv2.flip(frame, 1)
        faces = detector.detect_faces(frame)
        if not faces:
            print("[WARN] ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•ŠìŒ. ë‹¤ì‹œ ì‹œë„ ì¤‘...")
            continue
        face = faces[0]
        if face.get('confidence', 0) < 0.90:
            print("[WARN] ì–¼êµ´ ê°ì§€ ì‹ ë¢°ë„ ë‚®ìŒ. ìŠ¤í‚µ.")
            continue
        # ì–¼êµ´ ì •ë ¬ ì ìš©
        aligned_face = align_face(frame, face)
        processed_face = preprocess_face(aligned_face)
        embedding = extract_embedding(processed_face)
        if embedding is None or embedding.shape[0] != 512:
            print("[ERROR] ì„ë² ë”© ì˜¤ë¥˜ ë˜ëŠ” í¬ê¸° ë¶ˆì¼ì¹˜! ë‹¤ì‹œ ì‹œë„ ì¤‘...")
            continue
        samples.append([child_id, child_name] + embedding.tolist())
        print(f"[INFO] ìƒ˜í”Œ {len(samples)} ìˆ˜ì§‘ë¨.")

    cap.release()
    cv2.destroyAllWindows()

    if samples:
        new_data = pd.DataFrame(samples, columns=df.columns)
        df = pd.concat([df, new_data], ignore_index=True)
        df.to_csv(DB_PATH, index=False, float_format='%.6f')
        return {"status": 201, "message": f"âœ… ì–¼êµ´ ë“±ë¡ ì™„ë£Œ!", "data": {"child_id": child_id, "child_name": child_name}}
    return {"status": 400, "message": "âŒ ì–¼êµ´ ë“±ë¡ ì‹¤íŒ¨. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."}


def verify_child_face():
    """
    ì‹¤ì‹œê°„ ì¸ì¦: ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ì—ì„œ 10 í”„ë ˆì„ì„ ìº¡ì²˜í•˜ê³ ,
    ì–¼êµ´ ì •ë ¬ ë° ì „ì²˜ë¦¬ë¥¼ í†µí•´ ì„ë² ë”©ì„ ì¶”ì¶œí•œ í›„ í’ˆì§ˆì´ ë†’ì€ 3ê°œ í”„ë ˆì„ì˜ í‰ê·  ì„ë² ë”©ê³¼
    ë“±ë¡ëœ ê° ì•„ë™ì˜ í‰ê·  ì„ë² ë”©ì„ ë¹„êµí•˜ì—¬ ì¸ì¦í•©ë‹ˆë‹¤.
    """
    camera_index = get_available_camera()
    if camera_index is None:
        return {"status": 503, "message": "ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ê°€ ì—†ìŠµë‹ˆë‹¤."}

    cap = cv2.VideoCapture(camera_index, cv2.CAP_DSHOW)
    if not cap.isOpened():
        return {"status": 503, "message": "ì¹´ë©”ë¼ ì—°ê²° ì˜¤ë¥˜."}

    warmup_camera(cap)

    if not os.path.exists(DB_PATH):
        return {"status": 401, "message": "ë“±ë¡ëœ ì–¼êµ´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}

    df = pd.read_csv(DB_PATH, dtype={'child_id': int, 'child_name': str})
    if df.empty:
        return {"status": 401, "message": "ë“±ë¡ëœ ì–¼êµ´ì´ ì—†ìŠµë‹ˆë‹¤."}

    # ê° child_idë³„ í‰ê·  ì„ë² ë”© ê³„ì‚°
    grouped = df.groupby("child_id")
    avg_embeddings = {}
    names = {}
    for child_id, group in grouped:
        names[child_id] = group["child_name"].iloc[0]
        emb_array = group.iloc[:, 2:].values.astype(float)
        avg_embeddings[child_id] = np.mean(emb_array, axis=0)

    collected_embeddings = []
    quality_scores = []  # ì‹ ë¢°ë„ ì ìˆ˜ë¥¼ ì €ì¥
    # 10 í”„ë ˆì„ ìº¡ì²˜
    for _ in range(10):
        ret, frame = cap.read()
        if not ret:
            continue
        frame = cv2.flip(frame, 1)
        faces = detector.detect_faces(frame)
        if not faces:
            continue
        face = faces[0]
        if face.get('confidence', 0) < 0.90:
            continue
        # ì–¼êµ´ ì •ë ¬ ì ìš©
        aligned_face = align_face(frame, face)
        processed_face = preprocess_face(aligned_face)
        embedding = extract_embedding(processed_face)
        if embedding is not None and embedding.shape[0] == 512:
            collected_embeddings.append(embedding)
            quality_scores.append(face.get('confidence', 0))

    cap.release()
    cv2.destroyAllWindows()

    if not collected_embeddings:
        return {"status": 401, "message": "ì–¼êµ´ì„ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."}

    # í’ˆì§ˆ ì ìˆ˜ê°€ ë†’ì€ ìƒìœ„ 3ê°œ ì„ë² ë”© ì„ íƒ í›„ í‰ê·  ê³„ì‚°
    collected_embeddings = np.array(collected_embeddings)
    if len(collected_embeddings) > 3:
        indices = np.argsort(quality_scores)[::-1][:3]
        selected_embeddings = collected_embeddings[indices]
    else:
        selected_embeddings = collected_embeddings
    live_embedding = np.mean(selected_embeddings, axis=0)

    best_match = None
    best_similarity = 0
    for child_id, avg_emb in avg_embeddings.items():
        similarity = np.dot(live_embedding, avg_emb) / (np.linalg.norm(live_embedding) * np.linalg.norm(avg_emb))
        if similarity > best_similarity:
            best_similarity = similarity
            best_match = child_id

    if best_match and best_similarity > THRESHOLD:
        return {
            "status": 200,
            "message": "âœ… ì¸ì¦ ì„±ê³µ!",
            "child_id": int(best_match),
            "child_name": names[best_match],
            "similarity": round(best_similarity, 3)
        }
    return {"status": 401, "message": "âŒ ì¸ì¦ ì‹¤íŒ¨. ë“±ë¡ëœ ì–¼êµ´ê³¼ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."}

