import logging
import pyaudio
import numpy as np
import whisper
import time
import openai
from threading import Lock, Thread
import os
from app.extensions import socketio
from dotenv import load_dotenv

load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')

# Whisper ëª¨ë¸ ë¡œë“œ
model = whisper.load_model("large")

# ìŒì„± ì¸ì‹ ìƒíƒœ ë³€ìˆ˜ ë° Lock
is_recognizing = False
recognition_lock = Lock()
keep_listening = True      # ìŒì„± ì¸ì‹ì„ ê³„ì†í• ì§€ ì—¬ë¶€
gpt_processing = False     # í˜„ì¬ GPT ìš”ì²­ì„ ì²˜ë¦¬ ì¤‘ì¸ì§€ ì—¬ë¶€

# OpenAI API ì„¤ì •
openai.api_key = os.getenv("OPENAI_API_KEY")


def recognize_audio():
    global is_recognizing, keep_listening, gpt_processing

    with recognition_lock:
        is_recognizing = True

    CHUNK = 1024
    FORMAT = pyaudio.paInt16
    CHANNELS = 1
    RATE = 16000
    RECORD_SECONDS = 0.5

    p = pyaudio.PyAudio()
    stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)

    audio_buffer = []
    silence_threshold = 0.01    # ì£¼ë³€ ì†ŒìŒ ê°ì§€ë¥¼ ì¤„ì´ê¸° ìœ„í•´ ì„ê³„ì¹˜ ì„¤ì •
    silence_duration = 1.0      # ì¹¨ë¬µìœ¼ë¡œ ê°„ì£¼í•  ì‹œê°„
    last_speech_time = time.time()

    logging.info("ğŸ¤ ìŒì„± ì¸ì‹ ì‹œì‘")

    # keep_listeningì´ Trueì¸ ë™ì•ˆ ê³„ì† ìŒì„±ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    while keep_listening:
        # ì¼ì • ì‹œê°„ ë™ì•ˆ ì˜¤ë””ì˜¤ í”„ë ˆì„ì„ ì½ìŒ
        frames = [stream.read(CHUNK, exception_on_overflow=False)
                  for _ in range(0, int(RATE / CHUNK * RECORD_SECONDS))]
        audio_data = b''.join(frames)
        audio_np = np.frombuffer(audio_data, dtype=np.int16).astype(np.float32) / 32768.0

        # ì†ŒìŒ ì„ê³„ì¹˜ë¥¼ ì´ˆê³¼í•˜ë©´ ìŒì„±ì´ ê°ì§€ë˜ì—ˆë‹¤ê³  íŒë‹¨
        if np.abs(audio_np).mean() > silence_threshold:
            logging.debug("ğŸ™ ìŒì„± ê°ì§€ ì¤‘...")
            audio_buffer.append(audio_data)
            last_speech_time = time.time()
        # ì¼ì • ì‹œê°„ ì¹¨ë¬µì´ ì§€ì†ë˜ê³  ë²„í¼ì— ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì „ì‚¬ë¥¼ ì‹œë„
        elif time.time() - last_speech_time > silence_duration and audio_buffer:
            # ì´ë¯¸ GPT ìš”ì²­ì´ ì§„í–‰ ì¤‘ì´ë©´ ì´ë²ˆ ì…ë ¥ì€ ë¬´ì‹œí•˜ê³  ë²„í¼ë¥¼ ì´ˆê¸°í™”
            if not gpt_processing:
                logging.info("ğŸ›‘ ë§ ì¤‘ë‹¨ ê°ì§€ â†’ í…ìŠ¤íŠ¸ ë³€í™˜ ì‹œë„")
                full_audio = b''.join(audio_buffer)
                audio_buffer = []  # ë²„í¼ ì´ˆê¸°í™”

                try:
                    audio_np = np.frombuffer(full_audio, dtype=np.int16).astype(np.float32) / 32768.0
                    result = model.transcribe(audio_np, language="korean", temperature=0)
                    text = result["text"].strip()

                    if text:
                        logging.info(f"ğŸ“ í…ìŠ¤íŠ¸ ë³€í™˜ ì™„ë£Œ: {text}")
                        socketio.emit('recognized_text', {'text': text}, namespace='/')
                        # GPT ì²˜ë¦¬ë¥¼ ìœ„í•œ í”Œë˜ê·¸ ì„¤ì • í›„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì²˜ë¦¬
                        gpt_processing = True
                        Thread(target=get_gpt_response, args=(text,), daemon=True).start()
                except Exception as e:
                    logging.error(f"âŒ í…ìŠ¤íŠ¸ ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
            else:
                # GPT ìš”ì²­ ì§„í–‰ ì¤‘ì´ë©´ ë²„í¼ë¥¼ ë¹„ì›Œ ì¶”ê°€ ì…ë ¥ ë¬´ì‹œ
                audio_buffer = []
        # ë„ˆë¬´ ë¹ ë¥¸ ë£¨í”„ë¥¼ í”¼í•˜ê¸° ìœ„í•´ ì•½ê°„ íœ´ì‹
        time.sleep(0.01)

    stream.stop_stream()
    stream.close()
    p.terminate()
    logging.info("ğŸ›‘ ìŒì„± ì¸ì‹ ì¢…ë£Œ")
    with recognition_lock:
        is_recognizing = False


def get_gpt_response(user_input):
    global gpt_processing
    try:
        logging.info(f"ğŸ§  GPTì— ì§ˆë¬¸: {user_input}")
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": user_input}],
            max_tokens=150
        )
        logging.debug(f"GPT ì›ì‹œ ì‘ë‹µ: {response}")

        try:
            gpt_reply = response.choices[0].message['content'].strip()
        except AttributeError:
            gpt_reply = response.choices[0].text.strip()

        logging.info(f"ğŸ¤– GPT ì‘ë‹µ: {gpt_reply}")
        socketio.emit('gpt_response', {'response': gpt_reply}, namespace='/')
    except Exception as e:
        logging.error(f"âŒ GPT ìš”ì²­ ì¤‘ ì˜¤ë¥˜: {e}")
    finally:
        # GPT ì²˜ë¦¬ê°€ ëë‚˜ë©´ í”Œë˜ê·¸ ë¦¬ì…‹í•˜ì—¬ ë‹¤ìŒ ì…ë ¥ì„ ë°›ì„ ìˆ˜ ìˆë„ë¡ í•¨
        gpt_processing = False


def stop_recognition():
    global keep_listening
    keep_listening = False   # while ë£¨í”„ê°€ ì¢…ë£Œë¨
    logging.info("ğŸ›‘ ìŒì„± ì¸ì‹ ì¤‘ë‹¨")
    # ì¢…ë£Œ ì‹œ ëŒ€í™” ìš”ì•½ ìš”ì²­ (ìƒˆë¡œìš´ ì¸ì‹ì€ ì¬ì‹œì‘í•˜ì§€ ì•ŠìŒ)
    summary_prompt = "ìš°ë¦¬ ëŒ€í™”í•œ ëŒ€í™”ë‚´ìš© ìš”ì•½í•´ì„œ ì•Œë ¤ì¤˜"
    get_gpt_response(summary_prompt)
