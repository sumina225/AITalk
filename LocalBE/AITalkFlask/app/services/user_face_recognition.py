import cv2
import numpy as np
import pandas as pd
import os
from deepface import DeepFace
from mtcnn import MTCNN

DB_PATH = "face_db.csv"  # ì¹˜ë£Œì‚¬ ì–¼êµ´ DB íŒŒì¼
detector = MTCNN()  # MTCNN ì‚¬ìš©
THRESHOLD = 0.7  # ì¸ì¦ ì„ê³„ê°’ (í…ŒìŠ¤íŠ¸ì— ë”°ë¼ ì¡°ì •)
SECONDARY_THRESHOLD = 0.65  # ë³´ì¡° ì„ê³„ê°’ (í•„ìš” ì‹œ í™œìš©)


def get_available_camera():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ ì°¾ê¸°"""
    for i in range(5):  # ìµœëŒ€ 5ê°œ ì¹´ë©”ë¼ ê²€ì‚¬
        cap = cv2.VideoCapture(i, cv2.CAP_DSHOW)  # V4L2 ë°±ì—”ë“œ ì‚¬ìš©
        if cap.isOpened():
            print(f"âœ… ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼: {i}ë²ˆ")
            cap.release()
            return i
    print("ğŸš¨ ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ê°€ ì—†ìŠµë‹ˆë‹¤!")
    return None

def warmup_camera(cap):
    """ì¹´ë©”ë¼ ì›Œë°ì—… (3í”„ë ˆì„ ìŠ¤í‚µ)"""
    for _ in range(3):
        ret, _ = cap.read()
        if ret:
            print("[INFO] ì¹´ë©”ë¼ ì›Œë°ì—… ì™„ë£Œ")
            break


def align_face(frame, face):
    """
    ì–¼êµ´ ì •ë ¬ í•¨ìˆ˜.
    MTCNNì˜ ê²€ì¶œ ê²°ê³¼(face dict)ì—ì„œ 'box'ì™€ 'keypoints'ë¥¼ ì‚¬ìš©í•˜ì—¬,
    ì¢Œìš° ëˆˆì˜ ê°ë„ë¥¼ ê³„ì‚°í•˜ê³ , í•´ë‹¹ ê°ë„ë¡œ ì–¼êµ´ ì˜ì—­ì„ íšŒì „ì‹œí‚µë‹ˆë‹¤.
    """
    box = face['box']  # [x, y, w, h]
    keypoints = face['keypoints']
    x, y, w, h = box
    # ì›ë³¸ frameì—ì„œ ì–¼êµ´ ì˜ì—­ crop
    face_img = frame[y:y + h, x:x + w]
    # ì¢Œìš° ëˆˆ ì¢Œí‘œ (ì–¼êµ´ ì˜ì—­ ê¸°ì¤€ìœ¼ë¡œ ì¡°ì •)
    left_eye = (keypoints['left_eye'][0] - x, keypoints['left_eye'][1] - y)
    right_eye = (keypoints['right_eye'][0] - x, keypoints['right_eye'][1] - y)
    dx = right_eye[0] - left_eye[0]
    dy = right_eye[1] - left_eye[1]
    angle = np.degrees(np.arctan2(dy, dx))
    center = (w // 2, h // 2)
    M = cv2.getRotationMatrix2D(center, angle, 1)
    aligned_face = cv2.warpAffine(face_img, M, (w, h))
    return aligned_face


def preprocess_face(face_img):
    """ì–¼êµ´ ì „ì²˜ë¦¬: BGRâ†’RGB ë³€í™˜ í›„ 160x160 ë¦¬ì‚¬ì´ì¦ˆ"""
    face_img = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)
    face_img = cv2.resize(face_img, (160, 160))
    return face_img


def extract_embedding(processed_face, model="ArcFace"):
    """DeepFaceë¥¼ ì´ìš©í•´ ì–¼êµ´ ì„ë² ë”© ì¶”ì¶œ (512ì°¨ì›)"""
    try:
        analysis = DeepFace.represent(
            processed_face,
            model_name=model,
            detector_backend="mtcnn",
            enforce_detection=False
        )
        if not analysis or "embedding" not in analysis[0]:
            return None
        embedding = np.array(analysis[0]['embedding'], dtype=float)
        # 128ì°¨ì› ë²¡í„°ê°€ ë‚˜ì˜¤ë©´ 512ì°¨ì›ìœ¼ë¡œ íŒ¨ë”©
        if embedding.shape[0] == 128:
            embedding = np.pad(embedding, (0, 384), mode="constant")
        return embedding
    except Exception as e:
        print(f"[ERROR] ì–¼êµ´ ë²¡í„° ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return None


def register_user_face(therapist_id: int, therapist_name: str):
    """
    ì¹˜ë£Œì‚¬ ì–¼êµ´ ë“±ë¡:
    - ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ì—ì„œ ìµœëŒ€ 15íšŒ ì‹œë„ ì¤‘ 5ê°œ í’ˆì§ˆ ì¢‹ì€ ìƒ˜í”Œ ìˆ˜ì§‘
    - ì–¼êµ´ ì •ë ¬ ë° ì „ì²˜ë¦¬ í›„ ì„ë² ë”© ì¶”ì¶œí•˜ì—¬ CSV íŒŒì¼ì— ì €ì¥
    """
    camera_index = get_available_camera()
    if camera_index is None:
        return {"status": 503, "message": "ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ê°€ ì—†ìŠµë‹ˆë‹¤."}

    cap = cv2.VideoCapture(camera_index, cv2.CAP_DSHOW)
    if not cap.isOpened():
        return {"status": 503, "message": "ì¹´ë©”ë¼ ì—°ê²° ì˜¤ë¥˜."}

    warmup_camera(cap)

    # DB íŒŒì¼ ë¡œë“œ (ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±)
    if not os.path.exists(DB_PATH):
        df = pd.DataFrame(columns=["therapist_id", "therapist_name"] + [f"v{i}" for i in range(512)])
    else:
        df = pd.read_csv(DB_PATH, dtype={'therapist_id': int, 'therapist_name': str})
    # ë™ì¼ therapist_idê°€ ìˆìœ¼ë©´ ì œê±°
    df = df[df["therapist_id"] != therapist_id]

    samples = []
    attempts = 0
    while len(samples) < 5 and attempts < 15:
        ret, frame = cap.read()
        attempts += 1
        if not ret:
            print("[ERROR] ì´ë¯¸ì§€ ìº¡ì²˜ ì‹¤íŒ¨. ë‹¤ì‹œ ì‹œë„ ì¤‘...")
            continue
        frame = cv2.flip(frame, 1)
        faces = detector.detect_faces(frame)
        if not faces:
            print("[WARN] ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•ŠìŒ. ë‹¤ì‹œ ì‹œë„ ì¤‘...")
            continue
        for face in faces:
            if face.get('confidence', 0) < 0.90:
                print("[WARN] ì–¼êµ´ ê°ì§€ ì‹ ë¢°ë„ ë‚®ìŒ. ìŠ¤í‚µ.")
                continue
            # ì–¼êµ´ ì •ë ¬ ì ìš©
            aligned_face = align_face(frame, face)
            processed_face = preprocess_face(aligned_face)
            embedding = extract_embedding(processed_face)
            if embedding is None or embedding.shape[0] != 512:
                print("[ERROR] ì„ë² ë”© ì˜¤ë¥˜ ë˜ëŠ” í¬ê¸° ë¶ˆì¼ì¹˜! ë‹¤ì‹œ ì‹œë„ ì¤‘...")
                continue
            samples.append([therapist_id, therapist_name] + embedding.tolist())
            print(f"[INFO] ìƒ˜í”Œ {len(samples)} ìˆ˜ì§‘ë¨.")
            if len(samples) == 5:
                break

    cap.release()
    cv2.destroyAllWindows()

    if samples:
        new_data = pd.DataFrame(samples, columns=df.columns)
        df = pd.concat([df, new_data], ignore_index=True)
        df.to_csv(DB_PATH, index=False, float_format='%.6f')
        return {"status": 201, "message": f"âœ… ì–¼êµ´ ë“±ë¡ ì™„ë£Œ!", "data": {
        "therapist_id": therapist_id,
        "therapist_name": therapist_name
    }}
    return {"status": 400, "message": "âŒ ì–¼êµ´ ë“±ë¡ ì‹¤íŒ¨. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."}


def verify_user_face():
    """
    ì¹˜ë£Œì‚¬ ì–¼êµ´ ì¸ì¦:
    - ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ì—ì„œ 10í”„ë ˆì„ ìº¡ì²˜ í›„, ì–¼êµ´ ì •ë ¬ ë° ì „ì²˜ë¦¬í•˜ì—¬ ì„ë² ë”© ì¶”ì¶œ
    - í’ˆì§ˆì´ ë†’ì€ ìƒìœ„ 3ê°œ í”„ë ˆì„ì˜ í‰ê·  ì„ë² ë”©ì„ ê³„ì‚°í•˜ê³ , ë“±ë¡ëœ ê° ì¹˜ë£Œì‚¬ì˜ í‰ê·  ì„ë² ë”©ê³¼ ë¹„êµ
    """
    camera_index = get_available_camera()
    if camera_index is None:
        return {"status": 503, "message": "ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ê°€ ì—†ìŠµë‹ˆë‹¤."}

    cap = cv2.VideoCapture(camera_index, cv2.CAP_DSHOW)
    if not cap.isOpened():
        return {"status": 503, "message": "ì¹´ë©”ë¼ ì—°ê²° ì˜¤ë¥˜."}

    warmup_camera(cap)

    if not os.path.exists(DB_PATH):
        return {"status": 401, "message": "ë“±ë¡ëœ ì–¼êµ´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}

    df = pd.read_csv(DB_PATH, dtype={'therapist_id': int, 'therapist_name': str})
    if df.empty:
        return {"status": 401, "message": "ë“±ë¡ëœ ì–¼êµ´ì´ ì—†ìŠµë‹ˆë‹¤."}

    # ê° therapist_idë³„ í‰ê·  ì„ë² ë”© ê³„ì‚°
    grouped = df.groupby("therapist_id")
    avg_embeddings = {}
    names = {}
    for therapist_id, group in grouped:
        names[therapist_id] = group["therapist_name"].iloc[0]
        emb_array = group.iloc[:, 2:].values.astype(float)
        avg_embeddings[therapist_id] = np.mean(emb_array, axis=0)

    collected_embeddings = []
    quality_scores = []
    # 10 í”„ë ˆì„ ìº¡ì²˜
    for _ in range(10):
        ret, frame = cap.read()
        if not ret:
            continue
        frame = cv2.flip(frame, 1)
        faces = detector.detect_faces(frame)
        if not faces:
            continue
        face = faces[0]
        if face.get('confidence', 0) < 0.90:
            continue
        aligned_face = align_face(frame, face)
        processed_face = preprocess_face(aligned_face)
        embedding = extract_embedding(processed_face)
        if embedding is not None and embedding.shape[0] == 512:
            collected_embeddings.append(embedding)
            quality_scores.append(face.get('confidence', 0))

    cap.release()
    cv2.destroyAllWindows()

    if not collected_embeddings:
        return {"status": 401, "message": "ì–¼êµ´ì„ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."}

    collected_embeddings = np.array(collected_embeddings)
    if len(collected_embeddings) > 3:
        # ìƒìœ„ 3ê°œì˜ ì‹ ë¢°ë„ ë†’ì€ í”„ë ˆì„ ì„ íƒ
        indices = np.argsort(quality_scores)[::-1][:3]
        selected_embeddings = collected_embeddings[indices]
    else:
        selected_embeddings = collected_embeddings
    live_embedding = np.mean(selected_embeddings, axis=0)

    best_match = None
    best_similarity = 0
    for therapist_id, avg_emb in avg_embeddings.items():
        similarity = np.dot(live_embedding, avg_emb) / (np.linalg.norm(live_embedding) * np.linalg.norm(avg_emb))
        if similarity > best_similarity:
            best_similarity = similarity
            best_match = therapist_id

    if best_match and best_similarity > THRESHOLD:
        return {
            "status": 200,
            "message": "âœ… ì¸ì¦ ì„±ê³µ!",
            "therapist_id": int(best_match),
            "therapist_name": names[best_match],
            "similarity": round(best_similarity, 3)
        }
    return {"status": 401, "message": "âŒ ì¸ì¦ ì‹¤íŒ¨. ë“±ë¡ëœ ì–¼êµ´ê³¼ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."}

