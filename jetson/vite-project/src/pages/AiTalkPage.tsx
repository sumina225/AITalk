import { useEffect, useState } from 'react';
import { useLocation } from 'react-router-dom';
import { io } from 'socket.io-client';
import NavbarContainer from '../components/Common/NavbarContainer';
import BackPlaySelectButton from '../components/Common/BackPlaySelectButton';
import AiInfoContainer from '../components/Common/AiInfoContainer';

import './AiTalkPage.css';

export default function AiTalkPage() {
  const location = useLocation();

  // âœ… `childId` í™•ì¸
  const childId = location.state?.childId;
  console.log('ðŸ“Œ [AiTalkPage] ë°›ì€ childId:', childId);

  const [aiText, setAiText] = useState(
    location.state?.aiText || 'í†¡í†¡ì´ê°€ ëŒ€í™”í•  ì¤€ë¹„ ì¤‘ì´ì•¼...',
  );

  const [speechStatus, setSpeechStatus] = useState('ðŸŸ¡ í†¡í†¡ì´ ê¹¨ìš°ëŠ” ì¤‘ ...');

  useEffect(() => {
    console.log('ðŸ“¡ Initial state received:', location.state);

    if (location.state?.aiText) {
      setAiText(location.state.aiText);
    }
  }, [location.state]);

  useEffect(() => {
    const socket = io('http://localhost:5000'); // Flask ì„œë²„ ì£¼ì†Œ
    // âœ… "ìŒì„± ì¸ì‹ì´ ì‹œìž‘ë¨" ìƒíƒœ ê°ì§€ (ì‚¬ìš©ìžê°€ ë§í•  ì¤€ë¹„ ìƒíƒœ)
    socket.on('speech_ready', () => {
      console.log('ðŸŽ™ ìŒì„± ì¸ì‹ì´ ì‹œìž‘ë¨! (ì•„ì§ ë§í•˜ì§€ ì•ŠìŒ)');
      setSpeechStatus('ðŸŸ¢ ì§€ê¸ˆ ë§í•  ìˆ˜ ìžˆì–´ìš” !');
    });

    socket.on('speech_detected', () => {
      console.log('ðŸŽ™ ìŒì„± ê°ì§€ ì‹œìž‘! ì‚¬ìš©ìžê°€ ë§í•˜ê³  ìžˆìŒ...');
      setSpeechStatus('ðŸŽ¤ ìŒì„± ê°ì§€ ì¤‘ ...');
    });

    socket.on('speech_stopped', () => {
      console.log('ðŸ” [í”„ë¡ íŠ¸] speech_stopped ì´ë²¤íŠ¸ ìˆ˜ì‹ ë¨ â†’ ìƒíƒœ ë³€ê²½ ì‹¤í–‰');
      setTimeout(() => {
        setSpeechStatus('ðŸŸ¡ í†¡í†¡ì´ê°€ ìƒê° ì¤‘ ... ');
        console.log('ðŸŸ¡ [í”„ë¡ íŠ¸] ìƒíƒœ ì—…ë°ì´íŠ¸ ì™„ë£Œ: í†¡í†¡ì´ê°€ ìƒê° ì¤‘...');
      }, 0);
    });

    socket.on('gpt_response', (data) => {
      console.log('ðŸ¤– GPT ì‘ë‹µ ë„ì°©:', data);

      if (data.response) {
        setAiText(data.response);
      }

      if (data.audio) {
        console.log('ðŸŽµ ìŒì„± ìž¬ìƒ ì¤‘...');
        setSpeechStatus('ðŸ”´ í†¡í†¡ì´ê°€ ë§í•˜ëŠ” ì¤‘... ');

        const byteCharacters = atob(data.audio);
        const byteNumbers = new Array(byteCharacters.length)
          .fill(0)
          .map((_, i) => byteCharacters.charCodeAt(i));
        const byteArray = new Uint8Array(byteNumbers);
        const audioBlob = new Blob([byteArray], { type: 'audio/mp3' });

        const audioUrl = URL.createObjectURL(audioBlob);
        const audio = new Audio(audioUrl);

        audio.addEventListener('ended', () => {
          console.log('âœ… TTS ìž¬ìƒ ì™„ë£Œ');
          socket.emit('tts_finished');
        });

        audio
          .play()
          .catch((err) => console.error('âŒ Audio playback failed:', err));
      }
    });

    return () => {
      socket.disconnect();
    };
  }, []);

  return (
    <div>
      <NavbarContainer>
        <BackPlaySelectButton />
      </NavbarContainer>
      <div className="AiTalkContainer">
        <AiInfoContainer
          aiText={aiText}
          isTalking={speechStatus.includes('ðŸ”´')}
        />
        <p
          className={`speech-status ${
            speechStatus.includes('ðŸŸ¢')
              ? 'speak-ready'
              : speechStatus.includes('ðŸŽ¤')
                ? 'speaking'
                : speechStatus.includes('ðŸŸ¡')
                  ? 'thinking'
                  : speechStatus.includes('ðŸ”´')
                    ? 'talking'
                    : ''
          }`}
        >
          {speechStatus}
        </p>
      </div>
    </div>
  );
}
